# llama-on-local

code-nil.py: Without OpenAI <br>


code.py: With OpenAI <br>
