# llama-on-local

code-nil.py: Without OpenAI
code.py: With OpenAI
